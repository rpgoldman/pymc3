# Stubs for pymc3.model (Python 3.7)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.
from typing import Any, Optional, Dict, Mapping, Iterable


from collections import namedtuple
from theano.tensor.var import TensorVariable
from typing import Any, Optional, Dict
from pymc3 import _Point
from .distributions import Distribution

FlatView = namedtuple('FlatView', 'input, replacements, view')

class InstanceMethod:
    obj: Any = ...
    method_name: Any = ...
    def __init__(self, obj: Any, method_name: Any) -> None: ...
    def __call__(self, *args: Any, **kwargs: Any): ...

class Context:
    contexts: Any = ...
    _old_theano_config: Any = ...
    def __enter__(self): ...
    def __exit__(self, typ: Any, value: Any, traceback: Any) -> None: ...
    @classmethod
    def get_contexts(cls): ...
    @classmethod
    def get_context(cls): ...

def modelcontext(model: Any): ...

class Factor:
    def __init__(self, *args: Any, **kwargs: Any) -> None: ...
    @property
    def logp(self): ...
    @property
    def logp_elemwise(self): ...
    def dlogp(self, vars: Optional[Any] = ...): ...
    def d2logp(self, vars: Optional[Any] = ...): ...
    @property
    def logp_nojac(self): ...
    def dlogp_nojac(self, vars: Optional[Any] = ...): ...
    def d2logp_nojac(self, vars: Optional[Any] = ...): ...
    @property
    def fastlogp(self): ...
    def fastdlogp(self, vars: Optional[Any] = ...): ...
    def fastd2logp(self, vars: Optional[Any] = ...): ...
    @property
    def fastlogp_nojac(self): ...
    def fastdlogp_nojac(self, vars: Optional[Any] = ...): ...
    def fastd2logp_nojac(self, vars: Optional[Any] = ...): ...
    @property
    def logpt(self): ...
    @property
    def logp_nojact(self): ...

class InitContextMeta(type):
    def __call__(cls, *args: Any, **kwargs: Any): ...

class treelist(list):
    parent: Any = ...
    def __init__(self, iterable: Any = ..., parent: Optional[Any] = ...) -> None: ...
    append: Any = ...
    __iadd__: Any = ...
    extend: Any = ...
    def tree_contains(self, item: Any): ...
    def __setitem__(self, key: Any, value: Any) -> None: ...
#    def __imul__(self, other: Any) -> None: ...

class treedict(dict):
    parent: Any = ...
    def __init__(self, iterable: Any = ..., parent: Optional[Any] = ..., **kwargs: Any) -> None: ...
    __setitem__: Any = ...
    update: Any = ...
    def tree_contains(self, item: Any): ...

class ValueGradFunction:
    _grad_vars: Any = ...
    _extra_vars: Any = ...
    _extra_var_names: Any = ...
    _cost: Any = ...
    _ordering: Any = ...
    size: Any = ...
    _extra_are_set: bool = ...
    dtype: Any = ...
    _extra_vars_shared: Any = ...
    _theano_function: Any = ...
    def __init__(self, cost: Any, grad_vars: Any, extra_vars: Optional[Any] = ..., dtype: Optional[Any] = ..., casting: str = ..., **kwargs: Any) -> None: ...
    def set_extra_values(self, extra_vars: Any) -> None: ...
    def get_extra_values(self): ...
    def __call__(self, array: Any, grad_out: Optional[Any] = ..., extra_vars: Optional[Any] = ...): ...
    @property
    def profile(self): ...
    def dict_to_array(self, point: Any): ...
    def array_to_dict(self, array: Any): ...
    def array_to_full_dict(self, array: Any): ...
    def _build_joined(self, cost: Any, args: Any, vmap: Any): ...

class Model(Context,Factor, WithMemoization):
    __metaclass__ = InitContextMeta
    def __new__(cls, *args: Any, **kwargs: Any): ...
    name: Any = ...
    named_vars: Dict[str, Distribution] = ...
    free_RVs: Any = ...
    observed_RVs: Any = ...
    deterministics: Any = ...
    potentials: Any = ...
    missing_values: Any = ...
    def __init__(self, name: str = ..., model: Optional[Any] = ..., theano_config: Optional[Any] = ...) -> None: ...
    @property
    def model(self): ...
    @property
    def parent(self): ...
    @property
    def root(self): ...
    @property
    def isroot(self): ...
    @property
    def bijection(self): ...
    @property
    def dict_to_array(self): ...
    @property
    def ndim(self): ...
    @property
    def logp_array(self): ...
    @property
    def dlogp_array(self): ...
    def logp_dlogp_function(self, grad_vars: Optional[Any] = ..., **kwargs: Any): ...
    @property
    def logpt(self): ...
    @property
    def logp_nojact(self): ...
    @property
    def varlogpt(self): ...
    @property
    def datalogpt(self): ...
    @property
    def vars(self): ...
    @property
    def basic_RVs(self): ...
    @property
    def unobserved_RVs(self): ...
    @property
    def test_point(self): ...
    @property
    def disc_vars(self): ...
    @property
    def cont_vars(self): ...
    def Var(self, name: Any, dist: Any, data: Optional[Any] = ..., total_size: Optional[Any] = ...): ...
    def add_random_variable(self, var: Any) -> None: ...
    @property
    def prefix(self): ...
    def name_for(self, name: Any): ...
    def name_of(self, name: Any): ...
    def __getitem__(self, key: Any): ...
    def makefn(self, outs: Any, mode: Optional[Any] = ..., *args: Any, **kwargs: Any): ...
    def fn(self, outs: Any, mode: Optional[Any] = ..., *args: Any, **kwargs: Any): ...
    def fastfn(self, outs: Any, mode: Optional[Any] = ..., *args: Any, **kwargs: Any): ...
    def profile(self, outs: Any, n: int = ..., point: Optional[Any] = ..., profile: bool = ..., *args: Any, **kwargs: Any): ...
    def flatten(self, vars: Optional[Any] = ..., order: Optional[Any] = ..., inputvar: Optional[Any] = ...): ...
    def check_test_point(self, test_point: Optional[Any] = ..., round_vals: int = ...): ...
    def _repr_latex_(self, name: Optional[Any] = ..., dist: Optional[Any] = ...): ...
    __latex__: Any = ...

def fn(outs: Any, mode: Optional[Any] = ..., model: Optional[Any] = ..., *args: Any, **kwargs: Any): ...
def fastfn(outs: Any, mode: Optional[Any] = ..., model: Optional[Any] = ...): ...
def Point(*args: Any, **kwargs: Any): ...

class FastPointFunc:
    f: Any = ...
    def __init__(self, f: Any) -> None: ...
    def __call__(self, state: Any): ...

class LoosePointFunc:
    f: Any = ...
    model: Any = ...
    def __init__(self, f: Any, model: Any) -> None: ...
    def __call__(self, *args: Any, **kwargs: Any): ...
compilef = fastfn

class FreeRV(Factor, TensorVariable):
    dshape: Any = ...
    dsize: Any = ...
    distribution: Any = ...
    logp_elemwiset: Any = ...
    logp_sum_unscaledt: Any = ...
    logp_nojac_unscaledt: Any = ...
    total_size: Any = ...
    model: Any = ...
    scaling: Any = ...
    def __init__(self, type: Optional[Any] = ..., owner: Optional[Any] = ..., index: Optional[Any] = ..., name: Optional[Any] = ..., distribution: Optional[Any] = ..., total_size: Optional[Any] = ..., model: Optional[Any] = ...) -> None: ...
    def _repr_latex_(self, name: Optional[Any] = ..., dist: Optional[Any] = ...): ...
    __latex__: Any = ...
    @property
    def init_value(self): ...

class ObservedRV(Factor, TensorVariable):
    observations: Any = ...
    missing_values: Any = ...
    logp_elemwiset: Any = ...
    logp_sum_unscaledt: Any = ...
    logp_nojac_unscaledt: Any = ...
    total_size: Any = ...
    model: Any = ...
    distribution: Any = ...
    scaling: Any = ...
    def __init__(self, type: Optional[Any] = ..., owner: Optional[Any] = ..., index: Optional[Any] = ..., name: Optional[Any] = ..., data: Optional[Any] = ..., distribution: Optional[Any] = ..., total_size: Optional[Any] = ..., model: Optional[Any] = ...) -> None: ...
    def _repr_latex_(self, name: Optional[Any] = ..., dist: Optional[Any] = ...): ...
    __latex__: Any = ...
    @property
    def init_value(self): ...

class MultiObservedRV(Factor):
    name: Any = ...
    data: Any = ...
    missing_values: Any = ...
    logp_elemwiset: Any = ...
    logp_sum_unscaledt: Any = ...
    logp_nojac_unscaledt: Any = ...
    total_size: Any = ...
    model: Any = ...
    distribution: Any = ...
    scaling: Any = ...
    def __init__(self, name: Any, data: Any, distribution: Any, total_size: Optional[Any] = ..., model: Optional[Any] = ...) -> None: ...

def Deterministic(name: Any, var: Any, model: Optional[Any] = ...): ...
def Potential(name: Any, var: Any, model: Optional[Any] = ...): ...

class TransformedRV(TensorVariable):
    transformation: Any = ...
    model: Any = ...
    distribution: Any = ...
    dshape: Any = ...
    dsize: Any = ...
    transformed: Any = ...
    scaling: Any = ...
    def __init__(self, type: Optional[Any] = ..., owner: Optional[Any] = ..., index: Optional[Any] = ..., name: Optional[Any] = ..., distribution: Optional[Any] = ..., model: Optional[Any] = ..., transform: Optional[Any] = ..., total_size: Optional[Any] = ...) -> None: ...
    def _repr_latex_(self, name: Optional[Any] = ..., dist: Optional[Any] = ...): ...
    __latex__: Any = ...
    @property
    def init_value(self): ...
